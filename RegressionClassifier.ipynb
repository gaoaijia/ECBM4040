{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We import the required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log add data preprocessing and remove dropout for testing\n",
    "#Load necessary library\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import time\n",
    "#number of sample\n",
    "n=100\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from pickle file\n",
    "import six.moves.cPickle as pickle\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "data_dir = 'C:\\\\Users\\\\Mert Ketenci\\\\Desktop\\\\train\\\\train\\\\'\n",
    "data_dir=os.getcwd()\n",
    "output_file = 'trainpkl.gz'\n",
    "out_path = os.path.join(\"C:\\\\Users\\\\Mert Ketenci\\\\Desktop\\\\train\\\\train\\\\\", output_file)\n",
    "f_test = gzip.open(out_path, 'rb')\n",
    "test_set = pickle.load(f_test)\n",
    "f_test.close()\n",
    "# print (test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the pictures in an array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create labels and length list\n",
    "label=[]\n",
    "label = [int(x) for x in test_set[\"labels\"]]\n",
    "label = np.asarray(label)\n",
    "Pic_crop_Final =  test_set[\"images\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substract the mean of the image and define training-validation sets for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_train=1000\n",
    "n_train = int(n*0.8)\n",
    "Pic_crop_Final = test_set[\"images\"]\n",
    "plt.imshow(Pic_crop_Final[0].reshape([54,54,3]))\n",
    "x_train = np.array(Pic_crop_Final[:n_train])\n",
    "x_val = np.array(Pic_crop_Final[n_train:n])\n",
    "x_train = np.array(Pic_crop_Final[:n_train])\n",
    "x_val = np.array(Pic_crop_Final[n_train:n])\n",
    "y_train = label[:n_train]\n",
    "y_val = label[n_train:n]\n",
    "max_image = np.max(x_train, axis=0)\n",
    "min_image = np.min(x_train, axis=0)\n",
    "x_train = (x_train.astype(np.float32) - max_image)/(max_image-min_image)\n",
    "x_val = (x_val.astype(np.float32) - max_image)/(max_image-min_image)\n",
    "x_train = x_train.reshape(-1,54,54,3)\n",
    "x_val = x_val.reshape(-1,54,54,3)\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model (x, y, is_training=True, drop_rate=0.8):\n",
    "    if is_training == False:\n",
    "        drop_rate=0\n",
    "\n",
    "\n",
    "    with tf.variable_scope('CNN_1'):\n",
    "        conv = tf.layers.conv2d(x, filters=48, kernel_size=[5, 5], padding='same')\n",
    "        norm = tf.layers.batch_normalization(conv)\n",
    "        activation = tf.nn.relu(norm)\n",
    "        pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=2, padding='same')\n",
    "        hidden1 = pool  # 27 * 27 * 48\n",
    "        # print(hidden1.shape)\n",
    "\n",
    "    with tf.variable_scope('CNN_2'):\n",
    "        conv = tf.layers.conv2d(hidden1, filters=64, kernel_size=[5, 5], padding='same')\n",
    "        norm = tf.layers.batch_normalization(conv)\n",
    "        activation = tf.nn.relu(norm)\n",
    "        pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=1, padding='same')\n",
    "        hidden2 = pool  # 27 * 27 * 64\n",
    "        # print(hidden2.shape)\n",
    "\n",
    "    with tf.variable_scope('CNN_3'):\n",
    "        conv = tf.layers.conv2d(hidden2, filters=128, kernel_size=[5, 5], padding='same')\n",
    "        norm = tf.layers.batch_normalization(conv)\n",
    "        activation = tf.nn.relu(norm)\n",
    "        pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=2, padding='same')\n",
    "        hidden3 = pool  # 14 * 14 * 128\n",
    "        # print(hidden3.shape)\n",
    "\n",
    "    with tf.variable_scope('CNN_4'):\n",
    "        conv = tf.layers.conv2d(hidden3, filters=160, kernel_size=[5, 5], padding='same')\n",
    "        norm = tf.layers.batch_normalization(conv)\n",
    "        activation = tf.nn.relu(norm)\n",
    "        pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=1, padding='same')\n",
    "        hidden4 = pool  # 14 * 14 *160\n",
    "        # print(hidden4.shape)\n",
    "\n",
    "    with tf.variable_scope('CNN_5'):\n",
    "        conv = tf.layers.conv2d(hidden4, filters=192, kernel_size=[5, 5], padding='same')\n",
    "        norm = tf.layers.batch_normalization(conv)\n",
    "        activation = tf.nn.relu(norm)\n",
    "        pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=2, padding='same')\n",
    "        hidden5 = pool  # 7 * 7 * 192\n",
    "        # print(hidden5.shape)\n",
    "\n",
    "    with tf.variable_scope('CNN_6'):\n",
    "        conv = tf.layers.conv2d(hidden5, filters=192, kernel_size=[5, 5], padding='same')\n",
    "        norm = tf.layers.batch_normalization(conv)\n",
    "        activation = tf.nn.relu(norm)\n",
    "        pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=1, padding='same')\n",
    "        hidden6 = pool  # 7 * 7 * 192\n",
    "        # print(hidden6.shape)\n",
    "\n",
    "    with tf.variable_scope('CNN_7'):\n",
    "        conv = tf.layers.conv2d(hidden6, filters=192, kernel_size=[5, 5], padding='same')\n",
    "        norm = tf.layers.batch_normalization(conv)\n",
    "        activation = tf.nn.relu(norm)\n",
    "        pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=2, padding='same')\n",
    "        hidden7 = pool  # 4 * 4 * 192\n",
    "        # print(hidden7.shape)\n",
    "\n",
    "    with tf.variable_scope('CNN_8'):\n",
    "        conv = tf.layers.conv2d(hidden7, filters=192, kernel_size=[5, 5], padding='same')\n",
    "        norm = tf.layers.batch_normalization(conv)\n",
    "        activation = tf.nn.relu(norm)\n",
    "        pool = tf.layers.max_pooling2d(activation, pool_size=[2, 2], strides=1, padding='same')\n",
    "        hidden8 = pool  # 4 * 4 * 192\n",
    "\n",
    "    flatten = tf.reshape(hidden8, [-1, 4 * 4 * 192])\n",
    "\n",
    "    with tf.variable_scope('Hidden_1'):\n",
    "        dense = tf.layers.dense(flatten, units=8, activation=tf.nn.sigmoid)\n",
    "        dropout = tf.layers.dropout(dense, rate=drop_rate)\n",
    "        hidden9 = dropout\n",
    "\n",
    "    with tf.variable_scope('Hidedn_2'):\n",
    "        dense = tf.layers.dense(hidden9, units=8, activation=tf.nn.sigmoid)\n",
    "        dropout = tf.layers.dropout(dense, rate=drop_rate)\n",
    "        hidden10 = dropout\n",
    "\n",
    "    with tf.variable_scope('Output_layer'):\n",
    "        pred = tf.layers.dense(hidden10, units=1, activation=tf.nn.relu)\n",
    "    \n",
    "    loss  = tf.reduce_sum(tf.square(pred - y), name = 'loss_value')/100000\n",
    "\n",
    "    return loss,pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 \n",
      "9 batch training loss: 52.36391830444336\n",
      "9 batch training loss: 52.36391830444336 validation accuracy : 0.0%\n",
      "epoch 2 \n",
      "9 batch training loss: 54.85063934326172\n",
      "9 batch training loss: 54.85063934326172 validation accuracy : 0.0%\n",
      "epoch 3 \n",
      "9 batch training loss: 45.296077728271484\n",
      "9 batch training loss: 45.296077728271484 validation accuracy : 0.0%\n",
      "epoch 4 \n",
      "9 batch training loss: 457.4124755859375\n",
      "9 batch training loss: 457.4124755859375 validation accuracy : 0.0%\n",
      "epoch 5 \n",
      "9 batch training loss: 2.0442399978637695\n",
      "9 batch training loss: 2.0442399978637695 validation accuracy : 0.0%\n",
      "epoch 6 \n",
      "9 batch training loss: 1.5999999046325684\n",
      "9 batch training loss: 1.5999999046325684 validation accuracy : 0.0%\n",
      "epoch 7 \n",
      "9 batch training loss: 8.333919525146484\n",
      "9 batch training loss: 8.333919525146484 validation accuracy : 0.0%\n",
      "epoch 8 \n",
      "9 batch training loss: 104.27399444580078\n",
      "9 batch training loss: 104.27399444580078 validation accuracy : 0.0%\n",
      "epoch 9 \n",
      "9 batch training loss: 461.291748046875\n",
      "9 batch training loss: 461.291748046875 validation accuracy : 0.0%\n",
      "epoch 10 \n",
      "9 batch training loss: 71.72727966308594\n",
      "9 batch training loss: 71.72727966308594 validation accuracy : 0.0%\n",
      "epoch 11 \n",
      "9 batch training loss: 170.99176025390625\n",
      "9 batch training loss: 170.99176025390625 validation accuracy : 0.0%\n",
      "epoch 12 \n",
      "9 batch training loss: 5.005680084228516\n",
      "9 batch training loss: 5.005680084228516 validation accuracy : 0.0%\n",
      "epoch 13 \n",
      "9 batch training loss: 22.54207992553711\n",
      "9 batch training loss: 22.54207992553711 validation accuracy : 0.0%\n",
      "epoch 14 \n",
      "9 batch training loss: 58.291439056396484\n",
      "9 batch training loss: 58.291439056396484 validation accuracy : 0.0%\n",
      "epoch 15 \n",
      "9 batch training loss: 296.7792053222656\n",
      "9 batch training loss: 296.7792053222656 validation accuracy : 0.0%\n",
      "epoch 16 \n",
      "9 batch training loss: 50.2553596496582\n",
      "9 batch training loss: 50.2553596496582 validation accuracy : 0.0%\n",
      "epoch 17 \n",
      "9 batch training loss: 10.60807991027832\n",
      "9 batch training loss: 10.60807991027832 validation accuracy : 0.0%\n",
      "epoch 18 \n",
      "9 batch training loss: 54.333438873291016\n",
      "9 batch training loss: 54.333438873291016 validation accuracy : 0.0%\n",
      "epoch 19 \n",
      "9 batch training loss: 24.092639923095703\n",
      "9 batch training loss: 24.092639923095703 validation accuracy : 0.0%\n",
      "epoch 20 \n",
      "9 batch training loss: 22.188798904418945\n",
      "9 batch training loss: 22.188798904418945 validation accuracy : 0.0%\n",
      "epoch 21 \n",
      "9 batch training loss: 1.8698399066925049\n",
      "9 batch training loss: 1.8698399066925049 validation accuracy : 0.0%\n",
      "epoch 22 \n",
      "9 batch training loss: 58.12679672241211\n",
      "9 batch training loss: 58.12679672241211 validation accuracy : 0.0%\n",
      "epoch 23 \n",
      "9 batch training loss: 148.45806884765625\n",
      "9 batch training loss: 148.45806884765625 validation accuracy : 0.0%\n",
      "epoch 24 \n",
      "9 batch training loss: 54.766719818115234\n",
      "9 batch training loss: 54.766719818115234 validation accuracy : 0.0%\n",
      "epoch 25 \n",
      "9 batch training loss: 478.3642272949219\n",
      "9 batch training loss: 478.3642272949219 validation accuracy : 0.0%\n",
      "epoch 26 \n",
      "9 batch training loss: 169.27175903320312\n",
      "9 batch training loss: 169.27175903320312 validation accuracy : 0.0%\n",
      "epoch 27 \n",
      "9 batch training loss: 29.5143985748291\n",
      "9 batch training loss: 29.5143985748291 validation accuracy : 0.0%\n",
      "epoch 28 \n",
      "9 batch training loss: 1.2964799404144287\n",
      "9 batch training loss: 1.2964799404144287 validation accuracy : 0.0%\n",
      "epoch 29 \n",
      "9 batch training loss: 0.4933599829673767\n",
      "9 batch training loss: 0.4933599829673767 validation accuracy : 0.0%\n",
      "epoch 30 \n",
      "9 batch training loss: 1.4331200122833252\n",
      "9 batch training loss: 1.4331200122833252 validation accuracy : 0.0%\n",
      "epoch 31 \n",
      "9 batch training loss: 166.06784057617188\n",
      "9 batch training loss: 166.06784057617188 validation accuracy : 0.0%\n",
      "epoch 32 \n",
      "9 batch training loss: 32.97480010986328\n",
      "9 batch training loss: 32.97480010986328 validation accuracy : 0.0%\n",
      "epoch 33 \n",
      "9 batch training loss: 4.675519943237305\n",
      "9 batch training loss: 4.675519943237305 validation accuracy : 0.0%\n",
      "epoch 34 \n",
      "9 batch training loss: 34.07352066040039\n",
      "9 batch training loss: 34.07352066040039 validation accuracy : 0.0%\n",
      "epoch 35 \n",
      "9 batch training loss: 459.96990966796875\n",
      "9 batch training loss: 459.96990966796875 validation accuracy : 0.0%\n",
      "epoch 36 \n",
      "9 batch training loss: 54.66007995605469\n",
      "9 batch training loss: 54.66007995605469 validation accuracy : 0.0%\n",
      "epoch 37 \n",
      "9 batch training loss: 349.6304626464844\n",
      "9 batch training loss: 349.6304626464844 validation accuracy : 0.0%\n",
      "epoch 38 \n",
      "9 batch training loss: 141.7974395751953\n",
      "9 batch training loss: 141.7974395751953 validation accuracy : 0.0%\n",
      "epoch 39 \n",
      "9 batch training loss: 300.1374206542969\n",
      "9 batch training loss: 300.1374206542969 validation accuracy : 0.0%\n",
      "epoch 40 \n",
      "9 batch training loss: 297.2566223144531\n",
      "9 batch training loss: 297.2566223144531 validation accuracy : 0.0%\n",
      "epoch 41 \n",
      "9 batch training loss: 343.4632568359375\n",
      "9 batch training loss: 343.4632568359375 validation accuracy : 0.0%\n",
      "epoch 42 \n",
      "9 batch training loss: 349.9549560546875\n",
      "9 batch training loss: 349.9549560546875 validation accuracy : 0.0%\n",
      "epoch 43 \n",
      "9 batch training loss: 6.1317596435546875\n",
      "9 batch training loss: 6.1317596435546875 validation accuracy : 0.0%\n",
      "epoch 44 \n",
      "9 batch training loss: 1.3922399282455444\n",
      "9 batch training loss: 1.3922399282455444 validation accuracy : 0.0%\n",
      "epoch 45 \n",
      "9 batch training loss: 95.35199737548828\n",
      "9 batch training loss: 95.35199737548828 validation accuracy : 0.0%\n",
      "epoch 46 \n",
      "9 batch training loss: 10.078559875488281\n",
      "9 batch training loss: 10.078559875488281 validation accuracy : 0.0%\n",
      "epoch 47 \n",
      "9 batch training loss: 76.7520751953125\n",
      "9 batch training loss: 76.7520751953125 validation accuracy : 0.0%\n",
      "epoch 48 \n",
      "9 batch training loss: 10.003759384155273\n",
      "9 batch training loss: 10.003759384155273 validation accuracy : 0.0%\n",
      "epoch 49 \n",
      "9 batch training loss: 485.5308532714844\n",
      "9 batch training loss: 485.5308532714844 validation accuracy : 0.0%\n",
      "epoch 50 \n",
      "9 batch training loss: 44.77103805541992\n",
      "9 batch training loss: 44.77103805541992 validation accuracy : 0.0%\n",
      "epoch 51 \n",
      "9 batch training loss: 74.32231903076172\n",
      "9 batch training loss: 74.32231903076172 validation accuracy : 0.0%\n",
      "epoch 52 \n",
      "9 batch training loss: 301.6283264160156\n",
      "9 batch training loss: 301.6283264160156 validation accuracy : 0.0%\n",
      "epoch 53 \n",
      "9 batch training loss: 31.826398849487305\n",
      "9 batch training loss: 31.826398849487305 validation accuracy : 0.0%\n",
      "epoch 54 \n",
      "9 batch training loss: 456.4566955566406\n",
      "9 batch training loss: 456.4566955566406 validation accuracy : 0.0%\n",
      "epoch 55 \n",
      "9 batch training loss: 455.79742431640625\n",
      "9 batch training loss: 455.79742431640625 validation accuracy : 0.0%\n",
      "epoch 56 \n",
      "9 batch training loss: 77.77047729492188\n",
      "9 batch training loss: 77.77047729492188 validation accuracy : 0.0%\n",
      "epoch 57 \n",
      "9 batch training loss: 51.32095718383789\n",
      "9 batch training loss: 51.32095718383789 validation accuracy : 0.0%\n",
      "epoch 58 \n",
      "9 batch training loss: 459.80767822265625\n",
      "9 batch training loss: 459.80767822265625 validation accuracy : 0.0%\n",
      "epoch 59 \n",
      "9 batch training loss: 108.06895446777344\n",
      "9 batch training loss: 108.06895446777344 validation accuracy : 0.0%\n",
      "epoch 60 \n",
      "9 batch training loss: 103.71879577636719\n",
      "9 batch training loss: 103.71879577636719 validation accuracy : 0.0%\n",
      "epoch 61 \n",
      "9 batch training loss: 3.636159896850586\n",
      "9 batch training loss: 3.636159896850586 validation accuracy : 0.0%\n",
      "epoch 62 \n",
      "9 batch training loss: 1.0812000036239624\n",
      "9 batch training loss: 1.0812000036239624 validation accuracy : 0.0%\n",
      "epoch 63 \n",
      "9 batch training loss: 44.910400390625\n",
      "9 batch training loss: 44.910400390625 validation accuracy : 0.0%\n",
      "epoch 64 \n",
      "9 batch training loss: 297.72039794921875\n",
      "9 batch training loss: 297.72039794921875 validation accuracy : 0.0%\n",
      "epoch 65 \n",
      "9 batch training loss: 93.81536102294922\n",
      "9 batch training loss: 93.81536102294922 validation accuracy : 0.0%\n",
      "epoch 66 \n",
      "9 batch training loss: 467.7493591308594\n",
      "9 batch training loss: 467.7493591308594 validation accuracy : 0.0%\n",
      "epoch 67 \n",
      "9 batch training loss: 105.95943450927734\n",
      "9 batch training loss: 105.95943450927734 validation accuracy : 0.0%\n",
      "epoch 68 \n",
      "9 batch training loss: 323.70703125\n",
      "9 batch training loss: 323.70703125 validation accuracy : 0.0%\n",
      "epoch 69 \n",
      "9 batch training loss: 509.527099609375\n",
      "9 batch training loss: 509.527099609375 validation accuracy : 0.0%\n",
      "epoch 70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 batch training loss: 47.45471954345703\n",
      "9 batch training loss: 47.45471954345703 validation accuracy : 0.0%\n",
      "epoch 71 \n",
      "9 batch training loss: 1.3865599632263184\n",
      "9 batch training loss: 1.3865599632263184 validation accuracy : 0.0%\n",
      "epoch 72 \n",
      "9 batch training loss: 158.5968780517578\n",
      "9 batch training loss: 158.5968780517578 validation accuracy : 0.0%\n",
      "epoch 73 \n",
      "9 batch training loss: 12.568239212036133\n",
      "9 batch training loss: 12.568239212036133 validation accuracy : 0.0%\n",
      "epoch 74 \n",
      "9 batch training loss: 0.6590399742126465\n",
      "9 batch training loss: 0.6590399742126465 validation accuracy : 0.0%\n",
      "epoch 75 \n",
      "9 batch training loss: 137.75360107421875\n",
      "9 batch training loss: 137.75360107421875 validation accuracy : 0.0%\n",
      "epoch 76 \n",
      "9 batch training loss: 55.76839828491211\n",
      "9 batch training loss: 55.76839828491211 validation accuracy : 0.0%\n",
      "epoch 77 \n",
      "9 batch training loss: 3.1284799575805664\n",
      "9 batch training loss: 3.1284799575805664 validation accuracy : 0.0%\n",
      "epoch 78 \n",
      "9 batch training loss: 3.9896798133850098\n",
      "9 batch training loss: 3.9896798133850098 validation accuracy : 0.0%\n",
      "epoch 79 \n",
      "9 batch training loss: 142.12799072265625\n",
      "9 batch training loss: 142.12799072265625 validation accuracy : 0.0%\n",
      "epoch 80 \n",
      "9 batch training loss: 4.844079971313477\n",
      "9 batch training loss: 4.844079971313477 validation accuracy : 0.0%\n",
      "epoch 81 \n",
      "9 batch training loss: 4.71560001373291\n",
      "9 batch training loss: 4.71560001373291 validation accuracy : 0.0%\n",
      "epoch 82 \n",
      "9 batch training loss: 100.9818344116211\n",
      "9 batch training loss: 100.9818344116211 validation accuracy : 0.0%\n",
      "epoch 83 \n",
      "9 batch training loss: 79.12359619140625\n",
      "9 batch training loss: 79.12359619140625 validation accuracy : 0.0%\n",
      "epoch 84 \n",
      "9 batch training loss: 0.9814399480819702\n",
      "9 batch training loss: 0.9814399480819702 validation accuracy : 0.0%\n",
      "epoch 85 \n",
      "9 batch training loss: 375.90966796875\n",
      "9 batch training loss: 375.90966796875 validation accuracy : 0.0%\n",
      "epoch 86 \n",
      "9 batch training loss: 55.14543914794922\n",
      "9 batch training loss: 55.14543914794922 validation accuracy : 0.0%\n",
      "epoch 87 \n",
      "9 batch training loss: 24.93791961669922\n",
      "9 batch training loss: 24.93791961669922 validation accuracy : 0.0%\n",
      "epoch 88 \n",
      "9 batch training loss: 2.538879871368408\n",
      "9 batch training loss: 2.538879871368408 validation accuracy : 0.0%\n",
      "epoch 89 \n",
      "9 batch training loss: 45.1279182434082\n",
      "9 batch training loss: 45.1279182434082 validation accuracy : 0.0%\n",
      "epoch 90 \n",
      "9 batch training loss: 52.5995979309082\n",
      "9 batch training loss: 52.5995979309082 validation accuracy : 0.0%\n",
      "epoch 91 \n",
      "9 batch training loss: 54.667518615722656\n",
      "9 batch training loss: 54.667518615722656 validation accuracy : 0.0%\n",
      "epoch 92 \n",
      "9 batch training loss: 460.41845703125\n",
      "9 batch training loss: 460.41845703125 validation accuracy : 0.0%\n",
      "epoch 93 \n",
      "9 batch training loss: 456.5814208984375\n",
      "9 batch training loss: 456.5814208984375 validation accuracy : 0.0%\n",
      "epoch 94 \n",
      "9 batch training loss: 329.9195251464844\n",
      "9 batch training loss: 329.9195251464844 validation accuracy : 0.0%\n",
      "epoch 95 \n",
      "9 batch training loss: 77.40327453613281\n",
      "9 batch training loss: 77.40327453613281 validation accuracy : 0.0%\n",
      "epoch 96 \n",
      "9 batch training loss: 50.00856018066406\n",
      "9 batch training loss: 50.00856018066406 validation accuracy : 0.0%\n",
      "epoch 97 \n",
      "9 batch training loss: 458.2140808105469\n",
      "9 batch training loss: 458.2140808105469 validation accuracy : 0.0%\n",
      "epoch 98 \n",
      "9 batch training loss: 55.123199462890625\n",
      "9 batch training loss: 55.123199462890625 validation accuracy : 0.0%\n",
      "epoch 99 \n",
      "9 batch training loss: 29.661439895629883\n",
      "9 batch training loss: 29.661439895629883 validation accuracy : 0.0%\n",
      "epoch 100 \n",
      "9 batch training loss: 3.4447999000549316\n",
      "9 batch training loss: 3.4447999000549316 validation accuracy : 0.0%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.name_scope('inputs'):\n",
    "    x = tf.placeholder(tf.float32, shape=(None,54,54,3))\n",
    "    y =  tf.placeholder(tf.float32, shape=(None,))\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "num_train = x_train.shape[0]\n",
    "batch_size = 8\n",
    "epoches = 100\n",
    "num_batch = num_train//batch_size\n",
    "loss, pred = model(x, y)\n",
    "iter_total=0\n",
    "train_step = tf.train.GradientDescentOptimizer(1e-13).minimize(loss)\n",
    "\n",
    "cur_model_name = 'SVHN_{}'.format(int(time.time()))\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    saver = tf.train.Saver()\n",
    "    for e in range(epoches):\n",
    "        print(\"epoch {} \".format(e + 1))\n",
    "        for i in range(num_batch):\n",
    "            iter_total += 1\n",
    "            choice=np.random.choice(num_train, size=batch_size, replace=False)\n",
    "            batch_x, batch_y = x_train[choice], y_train[choice]\n",
    "            _, loss_tf = sess.run([train_step, loss],feed_dict={x:batch_x ,y:batch_y, is_training: True})\n",
    "            pred_tf = sess.run([pred],feed_dict={x:x_train, is_training: False})\n",
    "\n",
    "            if iter_total % 10 == 0:\n",
    "                pred_tf=np.asarray(pred_tf).astype(int)\n",
    "                diff=y_train.reshape(y_train.shape[0],1)-pred_tf.reshape(pred_tf.shape[1],1)\n",
    "                valid_acc = 1  - np.count_nonzero(diff)/diff.shape[0]\n",
    "\n",
    "                print('{} batch training loss: {}'.format(i,loss_tf))\n",
    "                print('{} batch training loss: {} validation accuracy : {}%'.format(i,loss_tf,valid_acc))\n",
    "\n",
    "                saver.save(sess, 'model/{}'.format(cur_model_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this model, we observed an unstable loss function. Eventhough we used a very small learning rate for the Adam optimizer loss function continued to flactuate. To avoid this, we even tried to use an activation function that provided vanishing gradient (sigmoid) but could not overcome the oscilation. For sigmoid unction we especially used a different way of input normalization. That is (input-max)/(max-min)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "688.383px",
    "left": "1357px",
    "right": "20px",
    "top": "81px",
    "width": "582.867px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

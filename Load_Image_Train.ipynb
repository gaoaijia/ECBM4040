{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Usage of the Notebook: \n",
    "\n",
    "The following code will perform the following action:\n",
    "\n",
    "(1) Read the downloaded images of SVHN\n",
    "\n",
    "(2) Using the blue bounding box marked on the digits of street number within each individual image, find the bounding box exclosing the full street number sequence\n",
    "\n",
    "(3) Extend the bounding box by 30% and crop the image to the size of the bounding box\n",
    "\n",
    "(4) Resize the image to size of (54,54,3).\n",
    "\n",
    "### Data Source & Description:\n",
    "\n",
    "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting. The dataset is similar in flavor to MNIST but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem. SVHN is obtained from house numbers in Google Street View images. There are three datasets available, train data (size 33401), test data (size 13068), and extra dataset (to be used if more data is needed for training). The datasets are provided in zip file.\n",
    "\n",
    "\n",
    "source: http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "### Final Output:\n",
    "\n",
    "The final output of this jupyter notebook gives one pickle file named \"trainpkl.gz\". This pickle file will be loaded during actual training to save the time from reading image directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Number of image is 33401, the file name start from 1 to 33402\n",
    "Train_no = 33402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shimeng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    }
   ],
   "source": [
    "#Before running, all the images need to be extracted from the zip folder downloaded from the website.\n",
    "#This code only reads the training image from un-zipped folder.\n",
    "\n",
    "from scipy import misc\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "X_train=[]\n",
    "#Make sure you change directory to your local directory where the unzipped images are stored\n",
    "directory = \"./train/\"\n",
    "img_type=\".png\"\n",
    "for i in range(1,Train_no):\n",
    "    image_name=[i,img_type]\n",
    "    values = ''.join(str(v) for v in image_name)\n",
    "    folder=[directory,values] \n",
    "    folder=''.join(folder)\n",
    "    image = misc.imread(folder)\n",
    "    X_train.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function to get the blue box position from the mat file provided with the training image\n",
    "def get_box_data(index, hdf5_data):\n",
    "    \n",
    "    meta_data = dict()\n",
    "    meta_data['height'] = []\n",
    "    meta_data['label'] = []\n",
    "    meta_data['left'] = []\n",
    "    meta_data['top'] = []\n",
    "    meta_data['width'] = []\n",
    "\n",
    "    def print_para(name, obj):\n",
    "        vals = []\n",
    "        if obj.shape[0] == 1:\n",
    "            vals.append(obj[0][0])\n",
    "        else:\n",
    "            for k in range(obj.shape[0]):\n",
    "                vals.append(int(hdf5_data[obj[k][0]][0][0]))\n",
    "        meta_data[name] = vals\n",
    "\n",
    "    box = hdf5_data['/digitStruct/bbox'][index]\n",
    "    hdf5_data[box[0]].visititems(print_para)\n",
    "    return meta_data\n",
    "\n",
    "def get_para(index, hdf5_data):\n",
    "    name = hdf5_data['/digitStruct/name']\n",
    "    return ''.join([chr(v[0]) for v in hdf5_data[name[index][0]].value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell will be able to provide you the cropped image in 54*54*3 format for training dataset\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#Make sure you change directory to your local directory where the mat files are stored\n",
    "#.mat file location\n",
    "mat_data = h5py.File('./train/digitStruct.mat')\n",
    "size = mat_data['/digitStruct/name'].size\n",
    "\n",
    "label_Final = []\n",
    "Pic_crop_Final = []\n",
    "#obtain label and basic parameters of each image\n",
    "for i in range(Train_no-1):\n",
    "    Array = np.array(X_train[i])\n",
    "    pic = get_para(i, mat_data)\n",
    "    box = get_box_data(i, mat_data)\n",
    "    label = box['label']\n",
    "    label_Final.append(''.join(str(int(x%10)) for x in label))\n",
    "\n",
    "    #Increase location by 30 on any edge of the box%\n",
    "    \n",
    "    H = int(round((max(box['top'])+max(box['height'])) *1.03))\n",
    "    L = int(round (min(box['left']) *(0.97)))\n",
    "    #ensure there is no negative dimension due to some of the picture have the weird locations\n",
    "    if L<0:\n",
    "        L =0\n",
    "    T = int(round (min(box['top'])*(0.97)))\n",
    "    if T<0:\n",
    "        T = 0\n",
    "    W = int(round((max (box ['left'])+ max(box['width']))*1.03))\n",
    "    #Crop the image\n",
    "    Pic_crop = Array [T:H,L:W]\n",
    "\n",
    "    #resize data and append to the created list\n",
    "\n",
    "    res_Pic_crop = cv2.resize(Pic_crop, dsize=(54, 54), interpolation=cv2.INTER_CUBIC)\n",
    "    Pic_crop_Final.append(res_Pic_crop)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reshape the data from 54,54,3 into 54*54*3, and convert both label and image into arrays\n",
    "\n",
    "c = []\n",
    "for i in range(Train_no-1):\n",
    "    a = np.reshape(Pic_crop_Final[i],54*54*3)\n",
    "    c.append(a)\n",
    "c = np.asarray(c)\n",
    "d = np.asarray(label_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pickle file and close the file\n",
    "import six.moves.cPickle as pickle\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "\n",
    "#Please change this directory to your local directory\n",
    "data_dir = '/Users/Shimeng/Documents/Master_Columbia_2018/E4040 NN and Deep Learning/Final Project/'\n",
    "output_file = 'trainpkl.gz'\n",
    "out_path = os.path.join(data_dir, output_file)\n",
    "\n",
    "#create document format\n",
    "out = {}\n",
    "out['labels'] = d\n",
    "out['images'] = c\n",
    "\n",
    "#save data\n",
    "p = gzip.open(out_path, 'wb')\n",
    "pickle.dump(out, p)\n",
    "p.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

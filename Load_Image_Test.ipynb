{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Usage of the Notebook: \n",
    "\n",
    "The following code will perform the action of reading the downloaded images of SVHN, leverage the blue bounding box of each individual image, construct a larger bounding box to include all digits within one image, increase the newly constructed bounding box by 30% and resize the image to 54*54*3 size\n",
    "\n",
    "### Data Source & Description:\n",
    "\n",
    "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting. The dataset is similar in flavor to MNIST but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem. SVHN is obtained from house numbers in Google Street View images. There are three datasets available, train data (size 33402), test data (size 13068), and extra dataset.\n",
    "\n",
    "\n",
    "source: http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "### Final Output:\n",
    "\n",
    "The final output of this jupyter notebook gives two pickle files named \"trainpkl.gz\" and \"testpkl.gz\". These two dataset will be used for the later model training process. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Number of dataset \n",
    "Test_no = 13068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shimeng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    }
   ],
   "source": [
    "#This is to read the training image from folder into jupyter notebook \n",
    "from scipy import misc\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "X_train=[]\n",
    "#Make sure you change directory to your local directory where the unzipped files are stored\n",
    "directory = \"./test/\"\n",
    "img_type=\".png\"\n",
    "for i in range(1,Test_no):\n",
    "    image_name=[i,img_type]\n",
    "    values = ''.join(str(v) for v in image_name)\n",
    "    folder=[directory,values] \n",
    "    folder=''.join(folder)\n",
    "    image = misc.imread(folder)\n",
    "    X_train.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function to get the blue box position from the mat file\n",
    "def get_box_data(index, hdf5_data):\n",
    "    \n",
    "    meta_data = dict()\n",
    "    meta_data['height'] = []\n",
    "    meta_data['label'] = []\n",
    "    meta_data['left'] = []\n",
    "    meta_data['top'] = []\n",
    "    meta_data['width'] = []\n",
    "\n",
    "    def print_para(name, obj):\n",
    "        vals = []\n",
    "        if obj.shape[0] == 1:\n",
    "            vals.append(obj[0][0])\n",
    "        else:\n",
    "            for k in range(obj.shape[0]):\n",
    "                vals.append(int(hdf5_data[obj[k][0]][0][0]))\n",
    "        meta_data[name] = vals\n",
    "\n",
    "    box = hdf5_data['/digitStruct/bbox'][index]\n",
    "    hdf5_data[box[0]].visititems(print_para)\n",
    "    return meta_data\n",
    "\n",
    "def get_para(index, hdf5_data):\n",
    "    name = hdf5_data['/digitStruct/name']\n",
    "    return ''.join([chr(v[0]) for v in hdf5_data[name[index][0]].value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell will be able to provide you the cropped image in 54*54*3 format for testing dataset\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#Make sure you change directory to your local directory where the mat file is stored\n",
    "#.mat file location\n",
    "mat_data = h5py.File('./test/digitStruct.mat')\n",
    "size = mat_data['/digitStruct/name'].size\n",
    "\n",
    "#print (box)\n",
    "label_Final = []\n",
    "Pic_crop_Final = []\n",
    "#obtain label and basic parameters of each image\n",
    "for i in range(Test_no-1):\n",
    "    Array = np.array(X_train[i])\n",
    "    pic = get_para(i, mat_data)\n",
    "    box = get_box_data(i, mat_data)\n",
    "    label = box['label']\n",
    "    label_Final.append(''.join(str(int(x%10)) for x in label))\n",
    "\n",
    "    #Increase location by 30 on any edge of the box%\n",
    "    \n",
    "    H = int(round((max(box['top'])+max(box['height'])) *1.03))\n",
    "    L = int(round (min(box['left']) *(0.97)))\n",
    "    #ensure there is no negative dimension due to some of the picture have the weird locations\n",
    "    if L<0:\n",
    "        L =0\n",
    "    T = int(round (min(box['top'])*(0.97)))\n",
    "    if T<0:\n",
    "        T = 0\n",
    "    W = int(round((max (box ['left'])+ max(box['width']))*1.03))\n",
    "    #Crop the image\n",
    "    Pic_crop = Array [T:H,L:W]\n",
    "\n",
    "    #resize data and append to the created list\n",
    "\n",
    "    res_Pic_crop = cv2.resize(Pic_crop, dsize=(54, 54), interpolation=cv2.INTER_CUBIC)\n",
    "    Pic_crop_Final.append(res_Pic_crop)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reshape the data from 54,54,3 into 54*54*3, and convert both label and image into arrays\n",
    "import numpy as np\n",
    "c = []\n",
    "for i in range(Test_no-1):\n",
    "    a = np.reshape(Pic_crop_Final[i],54*54*3)\n",
    "    c.append(a)\n",
    "c = np.asarray(c)\n",
    "d = np.asarray(label_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pickle file and close the file\n",
    "import six.moves.cPickle as pickle\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "\n",
    "#Please change this directory to your location directory\n",
    "data_dir = '/Users/Shimeng/Documents/Master_Columbia_2018/E4040 NN and Deep Learning/Final Project/'\n",
    "output_file = 'testpkl.gz'\n",
    "out_path = os.path.join(data_dir, output_file)\n",
    "\n",
    "#create document format\n",
    "out = {}\n",
    "out['labels'] = d\n",
    "out['images'] = c\n",
    "\n",
    "#save data\n",
    "p = gzip.open(out_path, 'wb')\n",
    "pickle.dump(out, p)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
